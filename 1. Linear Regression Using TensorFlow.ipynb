{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Linear Regression Using TensorFlow\n",
    "==================================\n",
    "\n",
    "In this notebook, we will go through the steps for performing Linear Regression on using TensorFlow. We will start with a simple problem and then scale it up using a real data example. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Loading Libraries and Dependencies\n",
    "----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Part 1: Simple Problem\n",
    "--------------------\n",
    "\n",
    "We all know that linear regression can be written as \n",
    "       \n",
    "       y = x*W + b \n",
    "       where x = Data Points\n",
    "             y = Outcome variable\n",
    "             W = Weights\n",
    "             b = Bias terms\n",
    "\n",
    "In this problem we will randomly generate the values of 'x' and then generate an equation of \n",
    "    y = 3*x + 10\n",
    "\n",
    "We will then train our tensorflow model to calculate the values of W (which is 3) and b (which is 10)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final model trained is y = x*[ 3.00000072] + [ 10.00000095]\n"
     ]
    }
   ],
   "source": [
    "# Initialize the x and y variables\n",
    "x = tf.placeholder(\"float\")\n",
    "y = tf.placeholder(\"float\")\n",
    "\n",
    "# Initialize the weight and bias terms\n",
    "W = tf.Variable([0.0], \"float\")\n",
    "b = tf.Variable([0.0], \"float\")\n",
    "\n",
    "# Generate the y' value which is the outcome of our equation\n",
    "y_model = tf.mul(x, W) + b\n",
    "\n",
    "# Define the cost function -- this is just the squared error of the original y and the calculated y\n",
    "cost = tf.square(y - y_model)\n",
    "\n",
    "# We now define the optimizer wiz GradientDescent with a learning rate of 0.5. We want it to minimize the cost\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.5).minimize(cost)\n",
    "\n",
    "# Now that we have all the variables needed, we will initialize them\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "\n",
    "# Create an empty list to store error\n",
    "error = []\n",
    "# Train our model\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for i in range(1000):\n",
    "        x_vals = np.random.rand()\n",
    "        y_vals = 3*x_vals + 10\n",
    "        _, err = sess.run([optimizer, cost], feed_dict={x:x_vals, y:y_vals})\n",
    "        error.append(err)\n",
    "    \n",
    "    W_ = sess.run(W)\n",
    "    b_ = sess.run(b)\n",
    "    print \"The final model trained is y = x*{0} + {1}\".format(W_, b_)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see our model has accurately found out the values of W and b as 3 and 10 respectively. This is exactly the value that we had provided as our training data.\n",
    "\n",
    "For the next step, we will use a dataset to generate the model. This will be a bit more complex as we will have more variables in x, thus resulting in a bigger W matrix and b array.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Part 2: Complex Problem\n",
    "-----------------------\n",
    "\n",
    "In this section we will load some data and then run a linear regression on that data using TensorFlow. We will use the same steps as above but this time it will be with a larger weight matrix and a larger bias array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at round 0 is 683.422912598\n",
      "Error at round 1000 is 26.8561878204\n",
      "Error at round 2000 is 22.9068012238\n",
      "Error at round 3000 is 22.6324672699\n",
      "Error at round 4000 is 22.5379657745\n",
      "Error at round 5000 is 22.4826049805\n",
      "Error at round 6000 is 22.4434165955\n",
      "Error at round 7000 is 22.4130401611\n",
      "Error at round 8000 is 22.3882846832\n",
      "Error at round 9000 is 22.3674411774\n",
      "Error at round 10000 is 22.3494987488\n",
      "Error at round 11000 is 22.3337993622\n",
      "Error at round 12000 is 22.3198757172\n",
      "Error at round 13000 is 22.3074131012\n",
      "Error at round 14000 is 22.2961483002\n",
      "Error at round 15000 is 22.2858963013\n",
      "Error at round 16000 is 22.2764873505\n",
      "Error at round 17000 is 22.2678070068\n",
      "Error at round 18000 is 22.2597446442\n",
      "Error at round 19000 is 22.2522258759\n",
      "The final model trained is Weights: [[ -7.91777563e+00]\n",
      " [  2.05953579e+01]\n",
      " [ -2.57939720e+00]\n",
      " [  1.92973912e-01]\n",
      " [ -2.50224799e-01]\n",
      " [  1.90705466e+00]\n",
      " [  6.81487098e-02]\n",
      " [ -6.58469296e+00]\n",
      " [  1.19433498e+01]\n",
      " [ -5.53810501e+01]\n",
      " [ -4.57343435e+00]\n",
      " [  6.99655151e+01]\n",
      " [ -2.68320847e+01]] + Bias : [ 22.53233719]\n"
     ]
    }
   ],
   "source": [
    "# We will use the Boston Data set that comes with sklearn\n",
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston(return_X_y=True)\n",
    "\n",
    "# Separating the target and the data\n",
    "data = boston[0]\n",
    "target = boston[1]\n",
    "\n",
    "# Normalize the data\n",
    "data_norm = (data - np.mean(data, axis = 0)) / np.var(data, axis = 0)\n",
    "\n",
    "# Let us initialize the variables like above\n",
    "x = tf.placeholder(\"float\", shape = [None, 13])\n",
    "y = tf.placeholder(\"float\", shape = [None, 1])\n",
    "\n",
    "# Initialize weights and bias\n",
    "W = tf.Variable(tf.ones([13, 1]))\n",
    "b = tf.Variable(tf.ones([1]))\n",
    "\n",
    "# Define the model for our training\n",
    "y_model = tf.matmul(x, W) + b\n",
    "\n",
    "# Define the cost function to minimize\n",
    "cost = tf.reduce_mean(tf.square(y - y_model))\n",
    "\n",
    "# Start our optimizer\n",
    "optimizer = tf.train.AdagradOptimizer(0.5).minimize(cost)\n",
    "\n",
    "# Start all variables\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "error = []\n",
    "# Start the training process\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(20000):\n",
    "        _, err = sess.run([optimizer, cost], feed_dict={x: data_norm, y: target.reshape(506, -1)})\n",
    "        error.append(err)\n",
    "        \n",
    "        if i % 1000 == 0:\n",
    "            print \"Error at round {0} is {1}\".format(i, err)\n",
    "        \n",
    "    W_ = sess.run(W)\n",
    "    b_ = sess.run(b)\n",
    "    \n",
    "    print \"The final model trained is Weights: {0} + Bias : {1}\".format(W_, b_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now compare these finding with sklear's linear model to check if our GradientDescent model has reached its minima. Sklearn using a closed form solution for Linear regression and hence is quicker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -7.90475175e+00]\n",
      " [  2.51861942e+01]\n",
      " [  9.79835276e-01]\n",
      " [  1.73104308e-01]\n",
      " [ -2.38482722e-01]\n",
      " [  1.87458334e+00]\n",
      " [  5.93933942e-01]\n",
      " [ -6.53060495e+00]\n",
      " [  2.31278565e+01]\n",
      " [ -3.49519998e+02]\n",
      " [ -4.46004154e+00]\n",
      " [  7.81295547e+01]\n",
      " [ -2.67430880e+01]] 22.5328063241\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lm = LinearRegression()\n",
    "lm.fit(data_norm, target)\n",
    "\n",
    "print lm.coef_.reshape(13, -1), lm.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
